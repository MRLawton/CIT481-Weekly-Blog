---
layout: post
title:  "Blog Post 9"
date:  2020-04-09 0:10:25 -0800
categories: jekyll blog
---
For the tenth week, I have been working on the last two lab assignments listed in the Vocareum portal. They focused mostly on the Beanstalk, application load balancer, launch configuration, and auto scaling services in the Amazon Web Services (AWS) online environment. The first lab specifically concentrated on how to utilize the Beanstalk service as to integrate and manage different components such as relational databases, EC2 instances, web applications, a load balancer, security groups, and monitoring features all together in tandem. It seems that this particular service provides a way to further develop, test, and automate a web application. An application using this feature of AWS must be written in a compatible programming language such as Python or Go. While I was following the instructions, I noticed a couple of details that seemed to be omitted from the listed steps. The first omission was the reason why multiple EC2 instances were required for the web application to function. If I recall correctly, there were two preset instances running in the dashboard section of the management console. As for the second omission, there seemed to be a bit of mystery surrounding the integration of the application within the AWS environment. I observed that the application was designed to introduce the user to various facts about Beanstalk by directing him or her to educational webpages regarding the service. They would provide basic information as to how it functions and interacts with other components in the AWS environment as well as perform basic operations in the management console. However, the tutorial did not really go over the sample code that was used during the lab session. I quickly noticed several files with the extension INF included in their names as I glanced through them. The type of files involved and their code are never really specified in any description during the session. It made wonder about the limitations and compatibility of the applications that can be implemented with this service. Furthermore, I saw that the set of provided instructions were not entirely accurate on one of the listed steps. The instance type of the EC2 instances were not located under the Instances row but rather found in the Capacity row. Overall, these vague elements of the lab didn't really detract from me completing it since was a quick and streamlined session that was presented in a simple, straightforward, and coherent manner. 

Besides a lack of details on certain parts of the aforementioned AWS activity, there were also some uncertainty when it came down to the sixth lab. Its purpose was to emphasize the existence of features such as the application load balancer, launch configurations, and auto scaling groups. I followed the steps that were provided to construct several cloud infrastructure components and designed them so they would interface with each other while online. I first had to create an Amazon Machine Image (AMI) to set the foundation for future EC2 instances since an AMI acts as a template in which the current state of a machine is saved for later use on the same computer or a different one. From there, I added on to the already established cloud infrastructure to properly setup the digital environment. Once the necessary infrastructure was in place, I proceeded in testing it by utilizing the application load balancer web service in a browser window. I achieved this by simulating a test load which then exerted an amount of stress on the system to analyze its capacity based on the way it was setup and its overall specifications. As this stress test progressed, I was able to view the online activity through certain areas of the management console. There were cloudwatch events that were setup to monitor the situation and trigger specific responses to these events. The actions that were specified during the setup process indicated that the cloud infrastructure should automatically increase its scale to include more EC2 instances once total capacity reached a certain point of utilization. In this case, that point was 60% and the new instances would launch with the specific configuration I had applied earlier during the lab session. This means that the new instances would be copies of the original web server that was used to generate the AMI. The included load balancer would distribute the HTTP internet traffic evenly throughout the network until the instances reached the maximum point of utilization, then the network would expand in size to accomadate this increase in web traffic. 


 