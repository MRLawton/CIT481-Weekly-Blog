---
layout: post
title:  "Blog Post 10"
date:  2020-04-15 0:10:25 -0800
categories: jekyll blog
---
For the eleventh week, I focused on completing an online tutorial to get a better grasp on how certain Amazon Web Services (AWS) interact with each other before I proceed constructing them by utilizing various Terraform resources in the Ubuntu terminal. The listed steps in the tutorial were divided into several sections that covered integral components of a functional Codepipeline. In the first section, there were multiple steps that were specifically designed to setup a CodeCommit data repository for use as a storage container to hold application data. This repository was then synchronized with a remote directory that is located on the local machine by establishing a link between the two storage units. To verify this connection was setup properly, the tutorial had me test it with the "git clone ssh://git-codecommit.us-west-2.amazonaws.com/v1/repos/MyDemoRepo" command. The repository called MyDemoRepo utilizes this command to push data onto the computer and stores it inside of the tmp directory. An assortment of different files can be stored within this directory such as images, text, web documents. I have not thoroughly explored this feature yet, so i do not actually know its limitations on the type of files that can be stored with the CodeCommit resource. I assume I can use it with a number of file extensions since there are references to it performing operations similar to Github in the AWS documentation webpages. I personally tested the service with files that had the jpg, png, gif, and txt extensions. They all worked in the repository and their inclusion did not throw any error messages. I was even able to perform a simple data transfer operation by specifying a set of commands such as "git add filename.extension", "git commit -m 'Added filename.extension'", and "git push -u origin master". These commands enabled me as the user to effectively push certain data onto the repository much like the previous command I mentioned allowed me to make a push request in which the data was sent from the repository to the local directory. The formation of a working repository and a remote directory is examined during the tutorial, but it omitted one crucial detail in this section which was the inclusion of the commands used to push data onto the repository. It showed how to create a data stream going in one direction but not the other. The absence of this information was explored in detail during the second section of the tutorial. I had this information from another tutorial and used it to place a few pictures and text files on the repository and also insert them on the remote directory. I then cleaned the area by deleting the test files I had moved around from place to place before transitioning to the next section of the tutorial. 

In the second section, I followed the instructions and together they had me add sample code to my CodeCommit repository. I did not deviate from the listed steps since all of its content was included in the section, and the necessary files that I required were accessible through a download link. The download was a compressed folder that possessed a hierarchical structure of directories and files to be utilized in the future steps of the tutorial. I stored this structure within the cloned MyDemoRepo folder of my tmp directory which I had constructed in the previous section. I unzipped the contents of the structure at this location and proceeded to perform a push operation on the specified data by using the "git add -A", "git commit -m 'Add sample application files'", and "git push" commands. These commands were similar to the ones I had used prior to following the steps outlined in section two. They uploaded the collection of directories and files to the master branch of the online data repository in the AWS management console. Together they compose a sample application that will be used to test the functionality of the Codepipeline and its connectivity with other acting agents such as CodeDeploy and in some cases CodeBuild. The second section solidifies the existence of the data repository by reinforcing its purpose. With data streams capable of being established in both directions, it cements the foundation CodeCommit lays down and will be useful when constructing the Codepipeline which acts as a pathway for the data on the specified network architecture.

From there, I moved on to the third section which appears to be centered on setting up an EC2 instance and installing the CodeDeploy agent onto it. The steps here had me create an instance role with the AmazonEC2RoleforAWSCodeDeploy to provide the necessary authorization credentials for a web server. I titled this role EC2InstanceRole, so the name would be intuitive in nature and easy to derive its meaning. Once I reached the point where I had to actually setup the instance is where I became stuck. I was able to specify some of the more basic cloud infrastructure information relating to the AMI (Amazon Machine Image) and the instance type, but at the configuration details webpage the console is asking me to enter a public subnet specified by a CIDR (Classless Inter-Domain Routing) block otherwise known as a range of IP (Internet Protocol) addresses that can be utilized by a particular instance. I am currently having difficulty here because I do not know what specific values to put in the required field. It doesn't seem to be referenced in the steps I am following and I have searched online for some instruction, but the examples I have found online seem to compute a range of IP addresses from an already specified CIDR block using a series of network and host bits. I am not really understanding how the math works out and pertains to the specific issue I am experiencing right now. I see that it is related to it, but the CIDR block is given in the beginning of each example, whereas I need to find a block that AWS will find acceptable for the EC2 instance. I have tried different combinations of numbers to satisfy this criterion but so far nothing has worked. I attempted to use the range 172.31.1.0/16 suggested by the professor, but I received a message from the interface that said it was not a valid block. The console will not allow me to move onto the next step until this issue is resolved. It is strange since it is not specifically mentioned in the listed steps to enter a CIDR block, and I was told to enable the auto-assign IP address feature for the instance. I even tried the same range of values specified by the default VPC itself, and surprisingly enough it accepted it as a viable CIDR block for a public subnet. However, I then received a new error message that stated I need to have a default CIDR block available for the VPC. This caused me to revert these changes back to current state as to not to overly complicate matters. At the moment, I am confused as to how to what value to use in this field and have reached to out to the professor for assistance. I will try to get through it again once I have heard back from her about this issue. After this tutorial is complete as a whole, I plan to modify my Terraform code, so it will compile correctly in the terminal instead of throwing errors involving undeclared variables in the root module. I will apply my notes and what I have learned about the Codepipeline service as to how it interacts with other cloud infrastructure components to the improvements I will implement in the future. By changing certain aspects of my code, I hope to get the Codepipeline up and running. 

